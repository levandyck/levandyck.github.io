% Encoding: UTF-8

@inproceedings{vandyck_hebart_dobs_2024b,
  title={Core neural dimensions of functionally selective areas in the human visual cortex},
  author={{van Dyck}, L. E. and Hebart, M. N., and Dobs, K.},
  presentationtype={poster},
  booktitle={Cognitive Computational Neuroscience (CCN)},
  address={Boston, MA, USA},
  month={August},
  year={2024},
  abstract={Prior research has extensively documented functional selectivity for categories within visual cortical areas, primarily by contrasting neural responses to images from various categories. However, such categorical approaches are less suitable to capture the diversity of neural representations within these areas. Do categoryselective areas encode holistic categories, or are they instead tuned to multifaceted features? To address this question, we employed non-negative matrix factorization (NMF) for analyzing human fMRI responses to natural images in face-, body-, and scene-selective areas, which uncovered a consistent set of interpretable neural dimensions across participants. These dimensions not only aligned with the areas' respective category preferences, but also revealed finer within-category distinctions, indicating selective tuning to diverse visual input features. Mapping these dimensions onto the cortical surface showed both clustered and distributed topographies, which accounted for overlaps between areas. Our results suggest that category-selective areas show multifaceted feature tuning, challenging traditional views and highlighting the complex interplay of neural dimensions in encoding visual information.},
  doi={https://2024.ccneuro.org/pdf/124_Paper_authored_ManuscriptAuthored.pdf}
}

@inproceedings{vandyck_hebart_dobs_2024a,
  title={Neural representational dimensions capture the nested functional organization of the human visual cortex},
  author={{van Dyck}, L. E. and Hebart, M. N. and Dobs, K.},
  presentationtype={talk},
  booktitle={SFB Workshop Categorization in Perception and Action: Minds, Models, Mechanisms},
  address={Marburg, Germany},
  month={June},
  year={2024}
}

@inproceedings{vandyck_dobs_hebart_2024,
  title={Core neural dimensions of functionally selective areas in the human visual cortex},
  author={{van Dyck}, L. E. and Dobs, K. and Hebart, M. N.},
  presentationtype={poster},
  booktitle={Workshop on CONCEPTS, ACTIONS, and OBJECTS (CAOs)},
  address={Rovereto, Italy},
  month={May},
  year={2024},
  abstract={Functionally selective visual brain areas enable efficient processing of concepts such as faces, bodies, and places. The application of traditional hypothesis-driven approaches has been invaluable to our current understanding of functional specialization, particularly in delineating functionally selective areas through comparisons of discrete categories. However, such methods are limited in their ability to provide comprehensive insights into the diverse neural representations within these areas. Recent data-driven approaches offer a more nuanced perspective by examining continuous dimensions. Here, we employed non-negative matrix factorization (NMF) to identify core neural dimensions directly from large-scale human fMRI responses to natural images in a variety of face-, body-, and place-selective areas. We discovered a diverse set of interpretable dimensions in all analyzed areas that were consistent across participants. As predicted, the most consistent dimensions in each area primarily aligned with its respective category preference, but also showed finer distinctions within that category, such as different body parts in body-selective areas or indoor and outdoor in place-selective areas. Moreover, the dimensions captured different subsets of the neural representational space, suggesting selective tuning to various aspects of a complex visual diet. Finally, visualization of dimension weights on the cortical surface revealed detailed topographies within each area with both clustered and distributed patterns, that even accounted for the overlap between functionally selective areas. Our results demonstrate an approach to deciphering the neural representations within functionally selective visual areas and provide multifaceted insights into how these areas process information.}
}

@article{vandyck_bremmer_dobs_2024,
  title={Artificial intelligence meets body sense: Task-driven neural networks reveal computational principles of the proprioceptive pathway},
  author={{van Dyck}, L. E. and Bremmer, F. and Dobs, K.},
  journal={Signal Transduction and Targeted Therapy},
  abbr={Sig. Transduct. Target. Ther.},
  volume={9},
  number={171},
  year={2024},
  note={[Open Access]},
  publisher={Springer Nature},
  doi={https://doi.org/10.1038/s41392-024-01870-9},
  abstract={In a recent study published in Cell, Marin Vargas and Bisi et al. present an innovative approach to unravel the computational principles underlying proprioceptive processing in non-human primates. Their findings showcase the utility of task-driven modeling in advancing neuroscience and offer translational potential by providing seminal insights into the goals and mechanisms by which the brain encodes body position and movements.},
  preview={sttt24.jpg}
}

@misc{vandyck_dobs_2023,
  title={Modellierung der biologischen Gesichtswahrnehmung mit Künstlicher Intelligenz},
  author={{van Dyck}, L. E. and Dobs, K.},
  howpublished={http://www.augenspiegel.com/zeitschrift.php/auge/cover/ausgabe-dezember-2023/ | DER AUGENSPIEGEL},
  month={December},
  year={2023},
  preview={}
}

@article{vandyck_gruber_2023,
  title={Modeling biological face recognition with deep convolutional neural networks},
  author={{van Dyck}, L. E. and Gruber, W. R.},
  journal={Journal of Cognitive Neuroscience},
  abbr = {J. Cogn. Neurosci.},
  volume={35},
  number={10},
  pages={1521--1537},
  year={2023},
  note={[Open Access]},
  publisher={MIT Press},
  doi={https://doi.org/10.1162/jocn_a_02040},
  abstract={Deep convolutional neural networks (DCNNs) have become the state-of-the-art computational models of biological object recognition. Their remarkable success has helped vision science break new ground, and recent efforts have started to transfer this achievement to research on biological face recognition. In this regard, face detection can be investigated by comparing face-selective biological neurons and brain areas to artificial neurons and model layers. Similarly, face identification can be examined by comparing in vivo and in silico multidimensional “face spaces.” In this review, we summarize the first studies that use DCNNs to model biological face recognition. On the basis of a broad spectrum of behavioral and computational evidence, we conclude that DCNNs are useful models that closely resemble the general hierarchical organization of face recognition in the ventral visual pathway and the core face network. In two exemplary spotlights, we emphasize the unique scientific contributions of these models. First, studies on face detection in DCNNs indicate that elementary face selectivity emerges automatically through feedforward processing even in the absence of visual experience. Second, studies on face identification in DCNNs suggest that identity-specific experience and generative mechanisms facilitate this particular challenge. Taken together, as this novel modeling approach enables close control of predisposition (i.e., architecture) and experience (i.e., training data), it may be suited to inform long-standing debates on the substrates of biological face recognition.},
  preview={jocn22.png}
}

@thesis{vandyck_2023,
  title={Unraveling top-down and bottom-up processes in theory of mind with layer fMRI},
  author={{van Dyck}, L. E.},
  school={University of Salzburg, Department of Psychology},
  abbr={Master's Thesis},
  year={2023},
  note={[Open Access]},
  abstract={Theory of Mind (ToM), the ability to reason about the mental states of others, is a crucial social skill of humans. Neuroimaging studies have found that the Temporo-Parietal Junction (TPJ) and an entire network of additional brain regions are specifically activated during mental state reasoning. Two common tasks that are used to investigate ToM are the False Belief (FB) task and the Social Animations (SA) task, which are thought to activate the posterior part (pTPJ) and the anterior part (aTPJ) of TPJ, respectively. While previous research has suggested potential explanations for this functional specialization, the exact mechanisms are not yet fully understood. In this study, high-resolution layer fMRI was used to examine neural activity in cortical layers of pTPJ and aTPJ during the FB and SA tasks. Firstly, the results corroborate the importance of the ToM network and especially TPJ in mental state reasoning. Secondly, a significant interaction between task and region was revealed, which underlines the expected functional specialization of TPJ clusters. Thirdly, the layer profiles of the two tasks indicated feedback-like activity, but when separated by region, pTPJ showed feedback-like activity for the FB task, while aTPJ displayed feedforward-like activity for the SA task. This pattern was further confirmed by a hierarchical cluster analysis. Overall, these findings suggest that the functional specialization, which is even reflected at the level of cortical layers, may enable TPJ to switch between detecting social cues externally and contemplating about them internally.},
  pdf={MastersThesis_vanDyck.pdf},
  preview={}
}

@article{vandyck_denzler_gruber_2022,
  title={Guiding visual attention in deep convolutional neural networks based on human eye movements},
  author={{van Dyck}, L. E. and Denzler, S. J. and Gruber, W. R.},
  journal={Frontiers in Neuroscience},
  volume={16},
  pages={975639},
  year={2022},
  note={[Open Access]},
  publisher={Frontiers},
  doi={https://doi.org/10.3389/fnins.2022.975639},
  abstract={Deep Convolutional Neural Networks (DCNNs) were originally inspired by principles of biological vision, have evolved into best current computational models of object recognition, and consequently indicate strong architectural and functional parallelism with the ventral visual pathway throughout comparisons with neuroimaging and neural time series data. As recent advances in deep learning seem to decrease this similarity, computational neuroscience is challenged to reverse-engineer the biological plausibility to obtain useful models. While previous studies have shown that biologically inspired architectures are able to amplify the human-likeness of the models, in this study, we investigate a purely data-driven approach. We use human eye tracking data to directly modify training examples and thereby guide the models’ visual attention during object recognition in natural images either toward or away from the focus of human fixations. We compare and validate different manipulation types (i.e., standard, human-like, and non-human-like attention) through GradCAM saliency maps against human participant eye tracking data. Our results demonstrate that the proposed guided focus manipulation works as intended in the negative direction and non-human-like models focus on significantly dissimilar image parts compared to humans. The observed effects were highly category-specific, enhanced by animacy and face presence, developed only after feedforward processing was completed, and indicated a strong influence on face detection. With this approach, however, no significantly increased human-likeness was found. Possible applications of overt visual attention in DCNNs and further implications for theories of face detection are discussed.},
  preview={frontneurosci22.png},
  altmetric={130035138}
}

@inproceedings{vandyck_denzler_gruber_2022,
  title={Analyzing and increasing the similarity of humans and deep convolutional neural networks in object recognition},
  author={{van Dyck}, L. E. and Denzler, S. J. and Gruber, W. R.},
  presentationtype={poster},
  booktitle={European Conference on Visual Perception (ECVP)},
  address={Nijmegen, The Netherlands},
  publisher={PERCEPTION},
  volume={51},
  pages={81},
  month={August},
  year={2022},
  organization={SAGE PUBLICATIONS LTD 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND},
  abstract={Deep convolutional neural networks (DCNNs) and the human ventral visual pathway share vast architectural and functional similarities in core object recognition. Recent insights have demonstrated that both hierarchical cascades can be compared in terms of behavior and underlying activation. However, current developments in computer vision decrease this similarity in state-of-the-art models. Therefore, to obtain useful, brain-like models for neuroscientific research, we aimed to assess and consequently increase their accordance throughout architectural and data-driven approaches. In a first proof-of-concept study, we demonstrate a comparison of human observers and three feedforward DCNNs with eye tracking and an attribution technique called GradCAM. The results revealed fundamentally different resolutions in measurements that need to be considered and provide further evidence that a biologically motivated modification of receptive field sizes increases the human-likeness of the model. In a second follow-up study, we used eye tracking data to directly manipulate training images and thereby draw the attention of the model to features that are important to human observers. Additionally, we refine this comparison by considering and exploring the time lag between cortical feedforward and feedback processing as well as consequently performed eye movements. With these approaches, we try to open new perspectives at the intersection of biological and computer vision research.}
}

@inproceedings{vandyck_denzler_schoellkopf_gruber_2022,
  title={Spatial similarities between human eye movements and deep convolutional neural network saliency maps across time},
  author={{van Dyck}, L. E. and Denzler, S. J. and Schöllkopf, C. P. and Gruber, W. R.},
  presentationtype={poster},
  booktitle={Salzburg Mind-Brain Annual Meeting (SAMBA)},
  address={Salzburg, Austria},
  month={July},
  year={2022},
  abstract={In recent years, a growing interest in the similarity between the brain's ventral visual pathway and deep convolutional neural networks (DCNNs) during visual processing led to numerous findings based on electrophysiological data. These studies revealed striking temporal and spatial alignment between the biological and artificial cascades. To date, however, only few attempts have been made to investigate the temporal similarity from the standpoint of spatial priorities during information processing. Therefore, in this study, we aim to test the existing evidence in the realm of eye tracking and compare object recognition in human observers and DCNNs through eye tracking heatmaps and GradCAM saliency maps. We investigate the reproducibility of the temporal correlations reported in neural activity by analyzing eye movements only. Moreover, we consider explanations regarding bottom-up/feedforward and top-down/recurrent processing mechanisms as well as their impact on viewing-behavior during object recognition. Finally, in a data-driven approach, we use the recorded eye tracking heatmaps to create modified image datasets for fine-tuning DCNNs and thereby influence the human-likeness of the models directly.}
}

@article{vandyck_kwitt_denzler_gruber_2021,
  title={Comparing object recognition in humans and deep convolutional neural networks—an eye tracking study},
  author={{van Dyck}, L. E. and Kwitt, R. and Denzler, S. J. and Gruber, W. R.},
  journal={Frontiers in Neuroscience},
  volume={15},
  pages={750639},
  year={2021},
  note={[Open Access]},
  publisher={Frontiers},
  doi={https://doi.org/10.3389/fnins.2021.750639},
  abstract={Deep convolutional neural networks (DCNNs) and the ventral visual pathway share vast architectural and functional similarities in visual challenges such as object recognition. Recent insights have demonstrated that both hierarchical cascades can be compared in terms of both exerted behavior and underlying activation. However, these approaches ignore key differences in spatial priorities of information processing. In this proof-of-concept study, we demonstrate a comparison of human observers (N = 45) and three feedforward DCNNs through eye tracking and saliency maps. The results reveal fundamentally different resolutions in both visualization methods that need to be considered for an insightful comparison. Moreover, we provide evidence that a DCNN with biologically plausible receptive field sizes called vNet reveals higher agreement with human viewing behavior as contrasted with a standard ResNet architecture. We find that image-specific factors such as category, animacy, arousal, and valence have a direct link to the agreement of spatial object recognition priorities in humans and DCNNs, while other measures such as difficulty and general image properties do not. With this approach, we try to open up new perspectives at the intersection of biological and computer vision research.},
  preview={frontneurosci21.png},
  altmetric={113860885}
}

@thesis{vandyck_gruber_2020,
  title={Seeing eye-to-eye? A comparison of object recognition performance in humans and deep convolutional neural networks under image manipulation},
  author={{van Dyck}, L. E.},
  school={University of Salzburg, Department of Psychology},
  abbr={Bachelor's Thesis},
  year={2020},
  note={[Open Access]},
  doi={https://doi.org/10.48550/arxiv.2007.06294},
  abstract={For a considerable time, deep convolutional neural networks (DCNNs) have reached human benchmark performance in object recognition. On that account, computational neuroscience and the field of machine learning have started to attribute numerous similarities and differences to artificial and biological vision. This study aims towards a behavioral comparison of visual core object recognition performance between humans and feedforward neural networks in a classification learning paradigm on an ImageNet data set. For this purpose, human participants (n = 65) competed in an online experiment against different feedforward DCNNs. The designed approach based on a typical learning process of seven different monkey categories included a training and validation phase with natural examples, as well as a testing phase with novel, unexperienced shape and color manipulations. Analyses of accuracy revealed that humans not only outperform DCNNs on all conditions, but also display significantly greater robustness towards shape and most notably color alterations. Furthermore, a precise examination of behavioral patterns highlights these findings by revealing independent classification errors between the groups. The obtained results show that humans contrast strongly with artificial feedforward architectures when it comes to visual core object recognition of manipulated images. In general, these findings are in line with a growing body of literature, that hints towards recurrence as a crucial factor for adequate generalization abilities.},
  preview={}
}

@article{hertlein_vandyck_2020,
  title={Predicting engagement in electronic surveillance in romantic relationships},
  author={Hertlein, K. M. and {van Dyck}, L. E.},
  journal={Cyberpsychology, Behavior, and Social Networking},
  volume={23},
  number={9},
  pages={604--610},
  year={2020},
  publisher={Mary Ann Liebert, Inc.},
  doi={https://doi.org/10.1089/cyber.2019.0424},
  preview={}
}