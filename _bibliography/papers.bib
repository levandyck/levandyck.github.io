% Encoding: UTF-8

@inproceedings{vandyck_hebart_dobs_2024b,
  title={Core neural dimensions of functionally selective areas in the human visual cortex},
  author={{van Dyck}, L. E. and Hebart, M. N., and Dobs, K.},
  presentationtype={poster},
  booktitle={Cognitive Computational Neuroscience (CCN)},
  address={Boston, MA, USA},
  month={August},
  year={2024},
  doi={https://2024.ccneuro.org/pdf/124_Paper_authored_ManuscriptAuthored.pdf},
  abstract={Prior research has extensively documented functional selectivity for categories within visual cortical areas, primarily by contrasting neural responses to images from various categories. However, such categorical approaches are less suitable to capture the diversity of neural representations within these areas. Do category-selective areas encode holistic categories, or are they instead tuned to multifaceted features? To address this question, we employed non-negative matrix factorization (NMF) for analyzing human fMRI responses to natural images in face-, body-, and scene-selective areas, which uncovered a consistent set of interpretable neural dimensions across participants. These dimensions not only aligned with the areas' respective category preferences, but also revealed finer within-category distinctions, indicating selective tuning to diverse visual input features. Mapping these dimensions onto the cortical surface showed both clustered and distributed topographies, which accounted for overlaps between areas. Our results suggest that category-selective areas show multifaceted feature tuning, challenging traditional views and highlighting the complex interplay of neural dimensions in encoding visual information.},
}

@inproceedings{vandyck_hebart_dobs_2024a,
  title={Neural representational dimensions capture the nested functional organization of the human visual cortex},
  author={{van Dyck}, L. E. and Hebart, M. N. and Dobs, K.},
  presentationtype={talk},
  booktitle={SFB Workshop Categorization in Perception and Action: Minds, Models, Mechanisms},
  address={Marburg, Germany},
  month={June},
  year={2024}
}

@inproceedings{vandyck_dobs_hebart_2024,
  title={Core neural dimensions of functionally selective areas in the human visual cortex},
  author={{van Dyck}, L. E. and Dobs, K. and Hebart, M. N.},
  presentationtype={poster},
  booktitle={Workshop on CONCEPTS, ACTIONS, and OBJECTS (CAOs)},
  address={Rovereto, Italy},
  month={May},
  year={2024}
}

@article{vandyck_bremmer_dobs_2024,
  title={Artificial intelligence meets body sense: Task-driven neural networks reveal computational principles of the proprioceptive pathway},
  author={{van Dyck}, L. E. and Bremmer, F. and Dobs, K.},
  journal={Signal Transduction and Targeted Therapy},
  abbr={Sig. Transduct. Target. Ther.},
  volume={9},
  number={171},
  year={2024},
  note={[Open Access]},
  publisher={Springer Nature},
  doi={https://doi.org/10.1038/s41392-024-01870-9},
  abstract={In a recent study published in Cell, Marin Vargas and Bisi et al. present an innovative approach to unravel the computational principles underlying proprioceptive processing in non-human primates. Their findings showcase the utility of task-driven modeling in advancing neuroscience and offer translational potential by providing seminal insights into the goals and mechanisms by which the brain encodes body position and movements.},
  preview={sttt24.jpg}
}

@misc{vandyck_dobs_2023,
  title={Modellierung der biologischen Gesichtswahrnehmung mit Künstlicher Intelligenz},
  author={{van Dyck}, L. E. and Dobs, K.},
  howpublished={https://app.augenspiegel.com/de/profiles/901d314af1eb/editions/28fb46e319fb7aaf3d1a/pages/page/13 | DER AUGENSPIEGEL},
  month={December},
  year={2023},
  preview={}
}

@article{vandyck_gruber_2023,
  title={Modeling biological face recognition with deep convolutional neural networks},
  author={{van Dyck}, L. E. and Gruber, W. R.},
  journal={Journal of Cognitive Neuroscience},
  abbr = {J. Cogn. Neurosci.},
  volume={35},
  number={10},
  pages={1521--1537},
  year={2023},
  note={[Open Access]},
  publisher={MIT Press},
  doi={https://doi.org/10.1162/jocn_a_02040},
  abstract={Deep convolutional neural networks (DCNNs) have become the state-of-the-art computational models of biological object recognition. Their remarkable success has helped vision science break new ground, and recent efforts have started to transfer this achievement to research on biological face recognition. In this regard, face detection can be investigated by comparing face-selective biological neurons and brain areas to artificial neurons and model layers. Similarly, face identification can be examined by comparing in vivo and in silico multidimensional “face spaces.” In this review, we summarize the first studies that use DCNNs to model biological face recognition. On the basis of a broad spectrum of behavioral and computational evidence, we conclude that DCNNs are useful models that closely resemble the general hierarchical organization of face recognition in the ventral visual pathway and the core face network. In two exemplary spotlights, we emphasize the unique scientific contributions of these models. First, studies on face detection in DCNNs indicate that elementary face selectivity emerges automatically through feedforward processing even in the absence of visual experience. Second, studies on face identification in DCNNs suggest that identity-specific experience and generative mechanisms facilitate this particular challenge. Taken together, as this novel modeling approach enables close control of predisposition (i.e., architecture) and experience (i.e., training data), it may be suited to inform long-standing debates on the substrates of biological face recognition.},
  preview={jocn22.png}
}

@thesis{vandyck_2023,
  title={Unraveling top-down and bottom-up processes in theory of mind with layer fMRI},
  author={{van Dyck}, L. E.},
  school={University of Salzburg, Department of Psychology},
  abbr={Master's Thesis},
  year={2023},
  note={[Open Access]},
  pdf={MastersThesis_vanDyck.pdf},
  abstract={Theory of Mind (ToM), the ability to reason about the mental states of others, is a crucial social skill of humans. Neuroimaging studies have found that the Temporo-Parietal Junction (TPJ) and an entire network of additional brain regions are specifically activated during mental state reasoning. Two common tasks that are used to investigate ToM are the False Belief (FB) task and the Social Animations (SA) task, which are thought to activate the posterior part (pTPJ) and the anterior part (aTPJ) of TPJ, respectively. While previous research has suggested potential explanations for this functional specialization, the exact mechanisms are not yet fully understood. In this study, high-resolution layer fMRI was used to examine neural activity in cortical layers of pTPJ and aTPJ during the FB and SA tasks. Firstly, the results corroborate the importance of the ToM network and especially TPJ in mental state reasoning. Secondly, a significant interaction between task and region was revealed, which underlines the expected functional specialization of TPJ clusters. Thirdly, the layer profiles of the two tasks indicated feedback-like activity, but when separated by region, pTPJ showed feedback-like activity for the FB task, while aTPJ displayed feedforward-like activity for the SA task. This pattern was further confirmed by a hierarchical cluster analysis. Overall, these findings suggest that the functional specialization, which is even reflected at the level of cortical layers, may enable TPJ to switch between detecting social cues externally and contemplating about them internally.},
  preview={}
}

@article{vandyck_denzler_gruber_2022,
  title={Guiding visual attention in deep convolutional neural networks based on human eye movements},
  author={{van Dyck}, L. E. and Denzler, S. J. and Gruber, W. R.},
  journal={Frontiers in Neuroscience},
  volume={16},
  pages={975639},
  year={2022},
  note={[Open Access]},
  publisher={Frontiers},
  doi={https://doi.org/10.3389/fnins.2022.975639},
  abstract={Deep Convolutional Neural Networks (DCNNs) were originally inspired by principles of biological vision, have evolved into best current computational models of object recognition, and consequently indicate strong architectural and functional parallelism with the ventral visual pathway throughout comparisons with neuroimaging and neural time series data. As recent advances in deep learning seem to decrease this similarity, computational neuroscience is challenged to reverse-engineer the biological plausibility to obtain useful models. While previous studies have shown that biologically inspired architectures are able to amplify the human-likeness of the models, in this study, we investigate a purely data-driven approach. We use human eye tracking data to directly modify training examples and thereby guide the models' visual attention during object recognition in natural images either toward or away from the focus of human fixations. We compare and validate different manipulation types (i.e., standard, human-like, and non-human-like attention) through GradCAM saliency maps against human participant eye tracking data. Our results demonstrate that the proposed guided focus manipulation works as intended in the negative direction and non-human-like models focus on significantly dissimilar image parts compared to humans. The observed effects were highly category-specific, enhanced by animacy and face presence, developed only after feedforward processing was completed, and indicated a strong influence on face detection. With this approach, however, no significantly increased human-likeness was found. Possible applications of overt visual attention in DCNNs and further implications for theories of face detection are discussed.},
  preview={frontneurosci22.png},
  altmetric={130035138}
}

@inproceedings{vandyck_denzler_gruber_2022,
  title={Analyzing and increasing the similarity of humans and deep convolutional neural networks in object recognition},
  author={{van Dyck}, L. E. and Denzler, S. J. and Gruber, W. R.},
  presentationtype={poster},
  booktitle={European Conference on Visual Perception (ECVP)},
  address={Nijmegen, The Netherlands},
  publisher={PERCEPTION},
  volume={51},
  pages={81},
  month={August},
  year={2022},
  organization={SAGE PUBLICATIONS LTD 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND}
}

@inproceedings{vandyck_denzler_schoellkopf_gruber_2022,
  title={Spatial similarities between human eye movements and deep convolutional neural network saliency maps across time},
  author={{van Dyck}, L. E. and Denzler, S. J. and Schöllkopf, C. P. and Gruber, W. R.},
  presentationtype={poster},
  booktitle={Salzburg Mind-Brain Annual Meeting (SAMBA)},
  address={Salzburg, Austria},
  month={July},
  year={2022}
}

@article{vandyck_kwitt_denzler_gruber_2021,
  title={Comparing object recognition in humans and deep convolutional neural networks—an eye tracking study},
  author={{van Dyck}, L. E. and Kwitt, R. and Denzler, S. J. and Gruber, W. R.},
  journal={Frontiers in Neuroscience},
  volume={15},
  pages={750639},
  year={2021},
  note={[Open Access]},
  publisher={Frontiers},
  doi={https://doi.org/10.3389/fnins.2021.750639},
  abstract={Deep convolutional neural networks (DCNNs) and the ventral visual pathway share vast architectural and functional similarities in visual challenges such as object recognition. Recent insights have demonstrated that both hierarchical cascades can be compared in terms of both exerted behavior and underlying activation. However, these approaches ignore key differences in spatial priorities of information processing. In this proof-of-concept study, we demonstrate a comparison of human observers (N = 45) and three feedforward DCNNs through eye tracking and saliency maps. The results reveal fundamentally different resolutions in both visualization methods that need to be considered for an insightful comparison. Moreover, we provide evidence that a DCNN with biologically plausible receptive field sizes called vNet reveals higher agreement with human viewing behavior as contrasted with a standard ResNet architecture. We find that image-specific factors such as category, animacy, arousal, and valence have a direct link to the agreement of spatial object recognition priorities in humans and DCNNs, while other measures such as difficulty and general image properties do not. With this approach, we try to open up new perspectives at the intersection of biological and computer vision research.},
  preview={frontneurosci21.png},
  altmetric={113860885}
}

@thesis{vandyck_gruber_2020,
  title={Seeing eye-to-eye? A comparison of object recognition performance in humans and deep convolutional neural networks under image manipulation},
  author={{van Dyck}, L. E.},
  school={University of Salzburg, Department of Psychology},
  abbr={Bachelor's Thesis},
  year={2020},
  note={[Open Access]},
  doi={https://doi.org/10.48550/arxiv.2007.06294},
  preview={}
}

@article{hertlein_vandyck_2020,
  title={Predicting engagement in electronic surveillance in romantic relationships},
  author={Hertlein, K. M. and {van Dyck}, L. E.},
  journal={Cyberpsychology, Behavior, and Social Networking},
  volume={23},
  number={9},
  pages={604--610},
  year={2020},
  publisher={Mary Ann Liebert, Inc.},
  doi={https://doi.org/10.1089/cyber.2019.0424},
  preview={}
}